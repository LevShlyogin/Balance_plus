# **Описание Платформы: Инфраструктура Брокера Сообщений**

**Версия:** 1.0  
**Статус:** Утверждено  
**Владелец:** Команда Платформы

## 1. Роль и ответственность

Инфраструктура Брокера Сообщений является центральным компонентом, обеспечивающим **асинхронное, слабо связанное взаимодействие** между микросервисами системы "Balance+". Она выступает в роли надежного почтового отделения, принимая сообщения-задачи от продюсеров (Сервиса Оркестрации) и гарантированно доставляя их консьюмерам (Расчётным Микросервисам).

Ключевые задачи, решаемые Брокером:
*   **Развязывание (Decoupling):** Продюсер и консьюмер не знают о существовании друг друга, что позволяет им развиваться и масштабироваться независимо.
*   **Поглощение пиковых нагрузок (Load Leveling):** Если Оркестратор генерирует много задач одновременно, они накапливаются в очереди, а worker'ы разбирают их в своем темпе, предотвращая перегрузку.
*   **Повышение отказоустойчивости:** Если worker-сервис временно недоступен, задачи для него не теряются, а остаются в очереди до тех пор, пока он не вернется в строй.

## 2. Технология и обоснование

*   **Выбранная технология:** **RabbitMQ**.
*   **Обоснование:**
    *   **Зрелость и надежность:** RabbitMQ — это проверенное временем, зрелое решение для реализации паттерна "Task/Command Queuing".
    *   **Богатые возможности маршрутизации:** Протокол AMQP предоставляет гибкие `exchanges`, которые идеально подходят для маршрутизации разных типов задач в разные очереди.
    *   **Гарантии доставки:** Поддерживает механизмы подтверждения (`acknowledgements`), персистентности и Dead-Lettering, что критически важно для нашей системы.
    *   **Идеальная интеграция с Celery:** Celery спроектирован для работы с RabbitMQ и нативно поддерживает все его продвинутые функции.

## 3. Топология и конфигурация

Для обеспечения чистоты и управляемости, мы принимаем следующую стандартизированную топологию.

```mermaid
graph TD
    subgraph "Продюсер"
        Orchestrator[<b>Сервис Оркестрации</b><br/><i>(Celery Producer)</i>]
    end

    subgraph "Инфраструктура RabbitMQ"
        TasksEX("
            <b>tasks_exchange</b><br/>
            <i>Тип: Direct</i><br/>
            <i>Свойство: Durable</i>
        ")
        
        TasksDLX("
            <b>tasks_dlx</b><br/>
            <i>Тип: Fanout</i><br/>
            <i>Свойство: Durable</i>
        ")
        
        CondenserQ("
            <b>condenser_calculation_queue</b><br/>
            <i>Durable, policy: deadLetterExchange=tasks_dlx</i>
        ")
        
        ValvesQ("
            <b>valves_calculation_queue</b><br/>
            <i>Durable, policy: deadLetterExchange=tasks_dlx</i>
        ")
        
        DeadLetterQ("
            <b>dead_letter_queue</b><br/>
            <i>Durable</i>
        ")
    end

    subgraph "Консьюмеры"
        CondenserWorker[<b>Condenser Worker</b><br/><i>(Celery Consumer)</i>]
        ValvesWorker[<b>Valves Worker</b><br/><i>(Celery Consumer)</i>]
        Monitoring["<b>Администратор / Мониторинг</b>"]
    end

    Orchestrator -- "msg(routing_key='calculation.condenser')" --> TasksEX
    Orchestrator -- "msg(routing_key='calculation.valves')" --> TasksEX
    
    TasksEX -- "route on 'calculation.condenser'" --> CondenserQ
    TasksEX -- "route on 'calculation.valves'" --> ValvesQ
    
    CondenserQ --> CondenserWorker
    ValvesQ --> ValvesWorker

    CondenserQ -. "nack(requeue=false)" .-> TasksDLX
    ValvesQ -. "nack(requeue=false)" .-> TasksDLX
    TasksDLX --> DeadLetterQ
    
    DeadLetterQ -- "Анализ сбойных задач" --> Monitoring
```

| Компонент | Назначение |
| :--- | :--- |
| **`tasks_exchange`** | **Центральный обменник** для всех расчётных задач. Тип `Direct` позволяет маршрутизировать сообщение в конкретную очередь на основе `routing_key`. |
| **Рабочие очереди** (`..._queue`) | Для каждого типа расчёта создается своя очередь. Это обеспечивает изоляцию: проблемы с одним типом расчётов не влияют на другие. |
| **`tasks_dlx`** | **Dead-Letter Exchange.** Обменник, который принимает "мёртвые" сообщения — те, которые worker не смог обработать и которые не нужно возвращать в очередь. |
| **`dead_letter_queue`** | **"Кладбище" сообщений.** Единая очередь, куда попадают все сбойные задачи для последующего анализа инженерами. Наличие сообщений в этой очереди — повод для алерта. |

## 4. Требования к надежности (Контракт для сервисов)

Все сервисы, взаимодействующие с RabbitMQ, **обязаны** следовать этим правилам:

| ID | Требование | Описание | Ответственный |
| :--- | :--- | :--- | :--- |
| **TR-MQ-1** | **Персистентность** | Все `exchanges`, `очереди` и `сообщения` должны быть `durable`. Это гарантирует, что они переживут перезапуск брокера. | Инфраструктура, Celery (по умолч.) |
| **TR-MQ-2** | **Подтверждения (ACKs)** | Консьюмеры **должны** работать в режиме ручного подтверждения (`acks_late=True` в Celery). Подтверждение (`ack`) отправляется **только после** полного и успешного завершения задачи. | Разработчик Worker'а |
| **TR-MQ-3** | **Качество обслуживания (QoS)** | Консьюмеры **должны** иметь `prefetch_count=1`. Это гарантирует, что worker не будет брать новые задачи, пока не закончит с текущей, обеспечивая справедливое распределение. | Конфигурация Celery Worker'а |
| **TR-MQ-4** | **Обработка сбоев** | При **невосстановимой ошибке** (ошибка в данных) worker **должен** отправить `nack` без `requeue`, чтобы сообщение ушло в DLQ. При **восстановимой ошибке** (недоступен Git) worker **должен** использовать механизм `retry` Celery. | Разработчик Worker'а |
| **TR-MQ-5** | **Кластеризация (Production)** | В production-среде RabbitMQ должен быть развернут в виде **кластера** из 3-х нод с включенным **зеркалированием** для всех рабочих очередей. | Команда DevOps / Платформы |

## 5. Требования к безопасности и мониторингу

*   **Безопасность:**
    *   Доступ к RabbitMQ защищен логином/паролем.
    *   Для каждого микросервиса используется отдельный пользователь с минимально необходимыми правами.
    *   Весь трафик шифруется с использованием TLS.
*   **Мониторинг:**
    *   Включен плагин `rabbitmq_prometheus` для сбора метрик.
    *   Включен `RabbitMQ Management UI` для администрирования.
    *   Настроены алерты в Grafana/Alertmanager на:
        *   Рост длины любой рабочей очереди выше порогового значения.
        *   Появление любого сообщения в `dead_letter_queue`.
        *   Отсутствие активных консьюмеров для любой из очередей.
